{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOmDHIDe23a7X2mPHVGk4WZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yeesem/Deep_Learning/blob/main/Data_Augmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8FRtwU_Ykmq"
      },
      "outputs": [],
      "source": [
        "# Download the dataset\n",
        "!wget https://storage.googleapis.com/tensorflow-1-public/course2/cats_and_dogs_filtered.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "# Extract the archive\n",
        "zip_ref = zipfile.ZipFile('./cats_and_dogs_filtered.zip','r')\n",
        "zip_ref.extractall('tmp/')\n",
        "zip_ref.close()\n",
        "\n",
        "# Assign training and validation set directories\n",
        "base_dir = 'tmp/cats_and_dogs_filtered'\n",
        "train_dir = os.path.join(base_dir,'train')\n",
        "validation_dir = os.path.join(base_dir,'validation')\n",
        "\n",
        "# Directory with training cats pictures\n",
        "train_cats_dir = os.path.join(train_dir,'cats')\n",
        "\n",
        "# Directory with training dogs pictures\n",
        "train_dogs_dir = os.path.join(train_dir,'dogs')\n",
        "\n",
        "# Directory with validation cats pictures\n",
        "validation_cats_dir = os.path.join(validation_dir,'cats')\n",
        "\n",
        "# Directory with validation dogs pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir,'dogs')"
      ],
      "metadata": {
        "id": "g0DvQheyYo8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "def create_model():\n",
        "  # Creates CNN with 4 convolutional layers\n",
        "  model = tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Conv2D(32,(3,3),activation = 'relu',input_shape = (150,150,3)),\n",
        "      tf.keras.layers.MaxPooling2D(2,2),\n",
        "      tf.keras.layers.Conv2D(64,(3,3),activation = 'relu'),\n",
        "      tf.keras.layers.MaxPooling2D(2,2),\n",
        "      tf.keras.layers.Conv2D(128,(3,3),activation = 'relu'),\n",
        "      tf.keras.layers.MaxPooling2D(2,2),\n",
        "      tf.keras.layers.Conv2D(128,(3,3),activation = 'relu'),\n",
        "      tf.keras.layers.MaxPooling2D(2,2),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(512,activation = 'relu'),\n",
        "      tf.keras.layers.Dense(1,activation = 'sigmoid')\n",
        "  ])\n",
        "\n",
        "  model.compile(loss = 'binary_crossentropy',\n",
        "                optimizer = RMSprop(learning_rate = 1e-4),\n",
        "                metrics = ['accuracy'])\n",
        "\n",
        "  return model\n",
        ""
      ],
      "metadata": {
        "id": "ej_8Ob5Ad2dJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "def DataGenerator(DataAugmentation = False):\n",
        "\n",
        "  if DataAugmentation == False:\n",
        "    train_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "  else:\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale = 1./255,\n",
        "        rotation_range = 40,\n",
        "        width_shift_range = 0.2,\n",
        "        height_shift_range = 0.2,\n",
        "        shear_range = 0.2,\n",
        "        zoom_range = 0.2,\n",
        "        horizontal_flip = True,\n",
        "        fill_mode = 'nearest'\n",
        "    )\n",
        "\n",
        "  test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "  train_generator = train_datagen.flow_from_directory(\n",
        "      train_dir,\n",
        "      target_size = (150,150),\n",
        "      batch_size = 20,\n",
        "      class_mode = 'binary'\n",
        "  )\n",
        "\n",
        "  validation_generator = test_datagen.flow_from_directory(\n",
        "      validation_dir,\n",
        "      target_size= (150,150),\n",
        "      batch_size = 20,\n",
        "      class_mode = 'binary'\n",
        "  )\n",
        "\n",
        "  return train_generator,validation_generator"
      ],
      "metadata": {
        "id": "ee_zxqaxfWZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(epoch,data_augmentation):\n",
        "    # Create a new model\n",
        "    model = create_model()\n",
        "    train_generator,validation_generator = DataGenerator(data_augmentation)\n",
        "    # Train the model\n",
        "    history = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch = 100, # 2000 images = batch_size * steps\n",
        "        epochs = epochs,\n",
        "        validation_data = validation_generator,\n",
        "        validation_steps = 50, # 1000 images = batch_size * steps\n",
        "        verbose = 2\n",
        "    )\n",
        "\n",
        "    return history"
      ],
      "metadata": {
        "id": "Hd_FcqBiiC53"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_loss_acc(history):\n",
        "  # Plot the training and validation loss and accuracy\n",
        "  acc = history.history['accuracy']\n",
        "  val_acc = history.history['val_accuracy']\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  epochs = range(len(acc))\n",
        "\n",
        "  # Plot the training and validation accuracy\n",
        "  plt.plot(epochs,acc,'bo',label = 'Training accuracy')\n",
        "  plt.plot(epochs,val_acc,'b',label = 'Validation accuracy')\n",
        "  plt.title('Training and validation accuracy')\n",
        "  plt.figure()\n",
        "\n",
        "  # Plot the training and validation loss\n",
        "  plt.plot(epochs,acc,'bo',label = 'Training accuracy')\n",
        "  plt.plot(epochs,val_acc,'b',label = 'Validation accuracy')\n",
        "  plt.title('Training and validation accuracy')\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "KDzqhvpRik2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model without data augmentation\n",
        "# Plot the training results\n",
        "history = train_model(20,False)\n",
        "plot_loss_acc(history)"
      ],
      "metadata": {
        "id": "uzOGRO2BkLAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model with data augmentation\n",
        "# Plot the training results\n",
        "history = train_model(20,False)\n",
        "plot_loss_acc(history)"
      ],
      "metadata": {
        "id": "l4jcivNIkOs0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}